# -*- coding: utf-8 -*-
"""kprm_scraper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s4Svlpnp-pdVGxV7uKLzEwVvb8zjtzfu
"""

!pip install bs4
!pip install requests


import requests
from bs4 import BeautifulSoup

"""Parser for each news and annoucements articules.

  News:
    'title' string: Tytuł newsu
    'date' string: Data publikacji podana przez KPRM
    'intro' string: Wstęp do artykułu
    'text' string: Artykuł
"""
#number of pages (news)
pages_n = 2

#list of news
news = []

for i in range(1, pages_n + 1):
    url = f'https://www.gov.pl/web/premier/wydarzenia?page={str(i)}1&size=10'
    page = requests.get(url)
    if page.status_code != 200:
        break
    soup = BeautifulSoup(page.content, 'html.parser')
    intro = soup.find('div', {'class': 'intro'}).text.strip()
    div = soup.find('div', {'class': 'art-prev art-prev--near-menu'})
    li_tags = div.find_all('li')


    for li in li_tags:
        link = li.find('a')
        if link:
            news_url = 'https://www.gov.pl' + link.get('href')
            news_page = requests.get(news_url)
            news_soup = BeautifulSoup(news_page.content, 'html.parser')

            title = news_soup.find('h2').text.strip()
            date = news_soup.find('p', {'class': 'event-date'}).text.strip()
            text = news_soup.find('div', {'class': 'editor-content'}).text.strip()

            news.append({
                'title': title,
                'date': date,
                'intro': intro,
                'text': text,
            })

print(news)

#number of pages (annoucements)
pages_a = 2

#list of annoucements
annoucement = []

for i in range(1, pages_a + 1):
    url = f'https://www.gov.pl/web/premier/komunikaty-cir?page={str(i)}&size=10'
    page = requests.get(url)
    if page.status_code != 200:
        break
    soup = BeautifulSoup(page.content, 'html.parser')
    div = soup.find('div', {'class': 'art-prev art-prev--near-menu'})
    li_tags = div.find_all('li')


    for li in li_tags:
        link = li.find('a')
        if link:
            annoucement_url = 'https://www.gov.pl' + link.get('href')
            annoucement_page = requests.get(annoucement_url)
            annoucement_soup = BeautifulSoup(annoucement_page.content, 'html.parser')

            title = annoucement_soup.find('h2').text.strip()
            date = annoucement_soup.find('p', {'class': 'event-date'}).text.strip()
            text = annoucement_soup.find('div', {'class': 'editor-content'}).text.strip()

            annoucement.append({
                'title': title,
                'date': date,
                'text': text,
            })

print(annoucement)

